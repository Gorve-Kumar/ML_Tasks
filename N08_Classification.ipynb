{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Binary Classification\n",
    "## Running Logistic Regression on the Heart Dataset\n",
    "- The dataset file is uploaded with this notebook as 'D6_Heart_Dataset_2.csv'. This dataset contains numeric data only.\n",
    "- Source: https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset?resource=download\n",
    "- This heart disease dataset is used for binary classification. \n",
    "- The dataset contains 304 observations.\n",
    "- It has 13 features and 1 class label with 0 and 1 values. \n",
    "- The attributes are discussed below.\n",
    "1. Age in years\n",
    "2. Gender (1 = male; 0 = female)\n",
    "3. Cp chest pain type:  \n",
    "   Value 1: typical angina,\n",
    "   Value 2: atypical angina,\n",
    "   Value 3: non-anginal pain\n",
    "   Value 4: asymptomatic,\n",
    "4. (trestbps) resting blood pressure (in mm Hg on admission to the hospital)\n",
    "5. (chol) serum cholestoral in mg/dl\n",
    "6. (fbs) (fasting blood sugar &gt; 120 mg/dl) (1 = true; 0 = false)\n",
    "7. (restecg) resting electrocardiographic results\n",
    "8. (thalach) maximum heart rate achieved\n",
    "9. (exang) exercise induced angina (1 = yes; 0 = no)\n",
    "10. (oldpeak) ST depression induced by exercise relative to rest\n",
    "11. (slope) the slope of the peak exercise ST segment\n",
    "12. (ca) number of major vessels (0-3) colored by flourosopy\n",
    "13. (thal) 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "14. target 1 or 0 (num) (the predicted attribute) diagnosis of heart disease (angiographic disease status):\n",
    "    Value 0: < 50% diameter narrowing,\n",
    "    Value 1: > 50% diameter narrowing,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and viewing the dataset\n",
    "dataset=pd.read_csv('D6_Heart_Dataset_2.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving features and target into separate dataframes\n",
    "features=dataset.drop('target',axis=1)\n",
    "target=dataset['target']\n",
    "#Splitting the dataset into train and test \n",
    "X_train,X_test,Y_train,Y_test = train_test_split(features, target,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Running Logictic Regression with standard settings\n",
    "- Regularization is applied by default in LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Creating logistic regression object\n",
    "#logistic_regression_model1 = LogisticRegression()\n",
    "logistic_regression_model1 = LogisticRegression(max_iter=1000)\n",
    "\n",
    "#Use the following statement if you want to try another solver like 'liblinear', otherwise default solver is 'lbfgs'.\n",
    "#logistic_regression_model1 = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "\n",
    "# Train model\n",
    "model1 = logistic_regression_model1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions on test data\n",
    "Y_pred_model1 = model1.predict(X_test)\n",
    "print(\"The accuracy is \"+str(metrics.accuracy_score(Y_test,Y_pred_model1)*100)+\"%\")\n",
    "print(confusion_matrix(Y_test, Y_pred_model1))\n",
    "print('Precision: ',metrics.precision_score(Y_test,Y_pred_model1))\n",
    "print('Recall score: ',metrics.recall_score(Y_test,Y_pred_model1))\n",
    "print('F1 score: ',metrics.f1_score(Y_test,Y_pred_model1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Running Logistic Regression with scaling (standardization)\n",
    "- Both test and train sets need to be scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us see values in X_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing train data\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "X_train_standardized=pd.DataFrame(standard_scaler.fit_transform(X_train)) # returns standardized array\n",
    "X_train_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing test data\n",
    "X_test_standardized=pd.DataFrame(standard_scaler.fit_transform(X_test))\n",
    "X_test_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Creating logistic regression object\n",
    "logistic_regression_model2 = LogisticRegression() #converged faster, no need to increase max_iter\n",
    "\n",
    "#Training the model\n",
    "model2 = logistic_regression_model2.fit(X_train_standardized, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the reduction in wall time with scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions on test data\n",
    "Y_pred_model2 = model2.predict(X_test_standardized)\n",
    "print(\"The accuracy is \"+str(metrics.accuracy_score(Y_test,Y_pred_model2)*100)+\"%\")\n",
    "print(confusion_matrix(Y_test, Y_pred_model2))\n",
    "print('Precision: ',metrics.precision_score(Y_test,Y_pred_model2))\n",
    "print('Recall score: ',metrics.recall_score(Y_test,Y_pred_model2))\n",
    "print('F1 score: ',metrics.f1_score(Y_test,Y_pred_model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=confusion_matrix(Y_test, Y_pred_model2)\n",
    "d.diagonal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Running Logistic Regression with scaling (Normalization)\n",
    "- Both test and train sets need to be scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the train data\n",
    "normal_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_normalized=pd.DataFrame(normal_scaler.fit_transform(X_train)) # returns standardized array\n",
    "X_train_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the test data\n",
    "X_test_normalized=pd.DataFrame(normal_scaler.fit_transform(X_test)) # returns standardized array\n",
    "X_test_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Creating logistic regression object\n",
    "logistic_regression_model3 = LogisticRegression() #converged faster, no need to increase max_iter\n",
    "\n",
    "#Training the model\n",
    "model3 = logistic_regression_model3.fit(X_train_normalized, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions\n",
    "Y_pred_model3 = model3.predict(X_test_normalized)\n",
    "print(\"The accuracy is \"+str(metrics.accuracy_score(Y_test,Y_pred_model3)*100)+\"%\")\n",
    "print(confusion_matrix(Y_test, Y_pred_model3))\n",
    "print('Precision: ',metrics.precision_score(Y_test,Y_pred_model3))\n",
    "print('Recall score: ',metrics.recall_score(Y_test,Y_pred_model3))\n",
    "print('F1 score: ',metrics.f1_score(Y_test,Y_pred_model3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Running K-Nearest Neighbour (a non-parametric algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = KNeighborsClassifier()\n",
    "model4.fit(X_train, Y_train)\n",
    "Y_pred_model4 = pd.DataFrame(model4.predict(X_test))\n",
    "print(\"The accuracy is \"+str(metrics.accuracy_score(Y_test,Y_pred_model4)*100)+\"%\")\n",
    "print(confusion_matrix(Y_test, Y_pred_model4))\n",
    "print('Precision: ',metrics.precision_score(Y_test,Y_pred_model4))\n",
    "print('Recall score: ',metrics.recall_score(Y_test,Y_pred_model4))\n",
    "print('F1 score: ',metrics.f1_score(Y_test,Y_pred_model4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Multiclass Classification\n",
    "## Running Logistic Regression on number dataset from sklearn\n",
    "- This dataset is one of the toy datasets of sklearn module.\n",
    "- Contains 1797 training examples.\n",
    "- Each training example is an 8x8 image of a hand-written digit.\n",
    "- Total classes: 10 (1 for each digit from 0 to 9)\n",
    "- Samples per class: 180 (approx)\n",
    "- Dimensions: 64\n",
    "- For more information visit: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and exploring the number dataset fron sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset from sklearn\n",
    "digit_dataset=load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing description of the dataset\n",
    "print(dir(digit_dataset))\n",
    "print(digit_dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying features\n",
    "digit_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying target\n",
    "digit_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking a peak on one of the images\n",
    "some_digit = digit_dataset.data[0]\n",
    "plt.imshow(some_digit.reshape(8, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looks like a 0, let's check the corresponding target value\n",
    "digit_dataset.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset\n",
    "X2_train,X2_test,Y2_train,Y2_test = train_test_split(digit_dataset.data, digit_dataset.target,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Running Logistic Regression\n",
    "- The model in Problem 2 is number 5 just to avoid name clashes with models of problem 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Creating logistic regression object\n",
    "#logistic_regression_model5 = LogisticRegression()\n",
    "logistic_regression_model5 = LogisticRegression(max_iter=10000)\n",
    "#Training the model\n",
    "model5 = logistic_regression_model5.fit(X2_train, Y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions\n",
    "Y2_pred_model5 = model5.predict(X2_test)\n",
    "print(\"The accuracy is \"+str(metrics.accuracy_score(Y2_test,Y2_pred_model5)*100)+\"%\")\n",
    "c_matrix=confusion_matrix(Y2_test, Y2_pred_model5)\n",
    "print(c_matrix)\n",
    "print('Precision: ',metrics.precision_score(Y2_test,Y2_pred_model5,average=None))\n",
    "print('Micro Precision: ',metrics.precision_score(Y2_test,Y2_pred_model5,average='micro'))\n",
    "print('Macro Precision: ',metrics.precision_score(Y2_test,Y2_pred_model5,average='macro'))\n",
    "print('Weighted Precision: ',metrics.precision_score(Y2_test,Y2_pred_model5,average='weighted'))\n",
    "print()\n",
    "print('Recall score: ',metrics.recall_score(Y2_test,Y2_pred_model5,average=None))\n",
    "print('Micro Recall score: ',metrics.recall_score(Y2_test,Y2_pred_model5,average='micro'))\n",
    "print('Macro Recall score: ',metrics.recall_score(Y2_test,Y2_pred_model5,average='macro'))\n",
    "print('Weighted Recall score: ',metrics.recall_score(Y2_test,Y2_pred_model5,average='weighted'))\n",
    "print()\n",
    "print('F1 score: ',metrics.f1_score(Y2_test,Y2_pred_model5,average=None))\n",
    "print('Micro F1 score: ',metrics.f1_score(Y2_test,Y2_pred_model5,average='micro'))\n",
    "print('Macro F1 score: ',metrics.f1_score(Y2_test,Y2_pred_model5,average='macro'))\n",
    "print('Weighted F1 score: ',\n",
    "      metrics.f1_score(Y2_test,Y2_pred_model5,average='weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Multiclass Multioutput Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating two labels (outputs) on same data\n",
    "- Label 1: For large numbers greater than 7\n",
    "- Label 2: For odd numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating two labels for train data\n",
    "y2_train_large = np.array(Y2_train >= 7)\n",
    "y2_multilabel_train = pd.DataFrame(data=y2_train_large, columns=['large'])\n",
    "y2_train_odd = np.array(Y2_train % 2 == 1)\n",
    "y2_multilabel_train['odd'] = y2_train_odd\n",
    "y2_multilabel_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating two labels for test data\n",
    "y2_test_large = np.array(Y2_test >= 7)\n",
    "y2_multilabel_test = pd.DataFrame(data=y2_test_large, columns=['large'])\n",
    "y2_test_odd = np.array(Y2_test % 2 == 1)\n",
    "y2_multilabel_test['odd'] = y2_test_odd\n",
    "y2_multilabel_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6: Running K-Nearest Neighbours on multiclass output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running K-Nearest Neighbours on train data and testing on test data\n",
    "model6 = KNeighborsClassifier()\n",
    "model6.fit(X2_train, y2_multilabel_train)\n",
    "Y2_pred_model6 = pd.DataFrame(model6.predict(X2_test),columns=['large','odd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_matrix for 'large'\n",
    "c_matrix_large=confusion_matrix(y2_multilabel_test['large'], Y2_pred_model6['large'])\n",
    "print(c_matrix_large)\n",
    "print('Precision: ',metrics.precision_score(y2_multilabel_test['large'], Y2_pred_model6['large']))\n",
    "print('Recall score: ',metrics.recall_score(y2_multilabel_test['large'], Y2_pred_model6['large']))\n",
    "print('F1 score: ',metrics.f1_score(y2_multilabel_test['large'], Y2_pred_model6['large']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_matrix for 'odd'\n",
    "c_matrix_odd=confusion_matrix(y2_multilabel_test['odd'], Y2_pred_model6['odd'])\n",
    "print(c_matrix_odd)\n",
    "print('Precision: ',metrics.precision_score(y2_multilabel_test['odd'], Y2_pred_model6['odd']))\n",
    "print('Recall score: ',metrics.recall_score(y2_multilabel_test['odd'], Y2_pred_model6['odd']))\n",
    "print('F1 score: ',metrics.f1_score(y2_multilabel_test['odd'], Y2_pred_model6['odd']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7: Running Logistic Regression on multiclass output\n",
    "- Unlike K-Nearest Neighbours, logistic regression doesnot support multioutput classification directly.\n",
    "- We will have to run it separately on each output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running Logistic Regression on first output 'large'\n",
    "\n",
    "#Creating logistic regression object\n",
    "logistic_regression_model7 = LogisticRegression(random_state=0, max_iter=10000)\n",
    "#Training the model\n",
    "model7_large = logistic_regression_model7.fit(X2_train, y2_multilabel_train['large'])\n",
    "model7_odd = logistic_regression_model7.fit(X2_train, y2_multilabel_train['odd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions for output 'large'\n",
    "Y2_pred_model7 = model7_large.predict(X2_test)\n",
    "print(\"The accuracy is \"+str(metrics.accuracy_score(y2_multilabel_test['large'],Y2_pred_model7)*100)+\"%\")\n",
    "c_matrix=confusion_matrix(y2_multilabel_test['large'],Y2_pred_model7)\n",
    "print(c_matrix)\n",
    "print('Precision: ',metrics.precision_score(y2_multilabel_test['large'],Y2_pred_model7))\n",
    "print('Recall score: ',metrics.recall_score(y2_multilabel_test['large'],Y2_pred_model7))\n",
    "print('F1 score: ',metrics.f1_score(y2_multilabel_test['large'],Y2_pred_model7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions for output 'odd'\n",
    "Y2_pred_model7 = model7_odd.predict(X2_test)\n",
    "print(\"The accuracy is \"+str(metrics.accuracy_score(y2_multilabel_test['odd'],Y2_pred_model7)*100)+\"%\")\n",
    "c_matrix=confusion_matrix(y2_multilabel_test['odd'],Y2_pred_model7)\n",
    "print(c_matrix)\n",
    "print('Precision: ',metrics.precision_score(y2_multilabel_test['odd'],Y2_pred_model7))\n",
    "print('Recall score: ',metrics.recall_score(y2_multilabel_test['odd'],Y2_pred_model7))\n",
    "print('F1 score: ',metrics.f1_score(y2_multilabel_test['odd'],Y2_pred_model7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
